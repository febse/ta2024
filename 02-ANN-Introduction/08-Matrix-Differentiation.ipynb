{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Matrix Differentiation Rules\n",
    "\n",
    "It is often convenient to express the derivatives in matrix form and use vectorized operations when updating the weights in neural networks. The reason for this is that vectorized operations in `numpy` for example are much faster than using Python loops. In this notebook, we will summarize a couple of useful rules for matrix differentiation.\n",
    "\n",
    ":::{#def-m-from-vec-n}\n",
    "Let $f: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{m}$ be a function that maps a m-dimensional vector to an n-dimensional vector. Then the derivative of $f$ with respect to a vector $x$ is a matrix (called the Jacobian matrix of $f$) of shape $m \\times n$ and is given by\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x} = \\begin{pmatrix}\n",
    "\\frac{\\partial f_1}{\\partial x_1} & \\cdots & \\frac{\\partial f_1}{\\partial x_n} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f_m}{\\partial x_1} & \\cdots & \\frac{\\partial f_m}{\\partial x_n}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{#exm-1-to-2}\n",
    "## $f: \\mathbb{R}^{1} \\to \\mathbb{R}^{2}$\n",
    "As an example, let's look at a function $f: \\mathbb{R}^{1} \\rightarrow \\mathbb{R}^{2}$ that maps a scalar to a 2-dimensional vector. The function is defined as\n",
    "\n",
    "$$\n",
    "f(x) = \\begin{pmatrix} x^2 \\\\ x^3 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "According to @def-m-from-vec-n the Jacobian matrix of $f$ is a $2 \\times 1$ matrix and is given by\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x} = \\begin{pmatrix}\n",
    "\\frac{\\partial f_1}{\\partial x} \\\\ \\frac{\\partial f_2}{\\partial x}\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "2x \\\\ 3x^2\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ":::{#def-matrix-to-scalar}\n",
    "\n",
    "Let $f: \\mathbb{R}^{m \\times n} \\rightarrow \\mathbb{R}$ be a function that maps a matrix to a scalar (e.g. a loss function). Then the derivative of $f$ with respect to a matrix $W$ is a matrix of the same shape as $W$ and is given by\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial W} = \\begin{pmatrix}\n",
    "\\frac{\\partial f}{\\partial W_{11}} & \\cdots & \\frac{\\partial f}{\\partial W_{1n}} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial W_{m1}} & \\cdots & \\frac{\\partial f}{\\partial W_{mn}}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{#thm-matrix-vector-by-vector}\n",
    "## Matrix Multiplication by Vector\n",
    "\n",
    "Let $A \\in \\mathbb{R}^{m \\times n}$ and $x \\in \\mathbb{R}^{n}$. Then the derivative of $Ax$ with respect to $x$ is $A^T$.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial Ax}{\\partial x} = A^T\n",
    "$$\n",
    ":::\n",
    ":::{.proof}\n",
    "\n",
    "Let $y = Ax$. Then $y_i = \\sum_{j=1}^{n} A_{ij}x_j$. The derivative of $y_i$ with respect to $x_k$ is\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y_i}{\\partial x_k} = A_{ik}\n",
    "$$\n",
    "\n",
    "Therefore, the derivative of $Ax$ with respect to $x$ is\n",
    "\n",
    "$$\n",
    "\\frac{\\partial Ax}{\\partial x} = \\begin{pmatrix}\n",
    "\\frac{\\partial y_1}{\\partial x_1} & \\cdots & \\frac{\\partial y_1}{\\partial x_n} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial y_m}{\\partial x_1} & \\cdots & \\frac{\\partial y_m}{\\partial x_n}\n",
    "\\end{pmatrix} = A^T\n",
    "$$\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{#thm-vector-by-vector}\n",
    "## Vector Derivative with Respect to Itself\n",
    "\n",
    "Let $x \\in \\mathbb{R}^{n}$. Then the derivative of $x$ with respect to $x$ is an $n \\times n$ matrix with 1s on the diagonal and 0s elsewhere.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial x}{\\partial x} = \\begin{pmatrix}\n",
    "\\frac{\\partial x_1}{\\partial x_1} & \\cdots & \\frac{\\partial x_1}{\\partial x_n} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial x_n}{\\partial x_1} & \\cdots & \\frac{\\partial x_n}{\\partial x_n}\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "1 & 0 & \\cdots & 0 \\\\\n",
    "0 & 1 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\cdots & 1\n",
    "\\end{pmatrix}\n",
    " = I_n\n",
    "$$\n",
    "\n",
    "where $I_n$ is the identity matrix of size $n \\times n$.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{#thm-elementwise-function-vector}\n",
    "## Derivative of Elementwise Applied Function with Respect to Vector\n",
    "\n",
    "Let $f: \\mathbb{R} \\to \\mathbb{R}$ be a scalar function that is applied elementwise to a vector $x \\in \\mathbb{R}^{n}$. Then the derivative of $y = f(x)$ with respect to $x$ is a diagonal matrix with the derivative of $f$ with respect to $x_i$ on the diagonal.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial x} = \\begin{pmatrix}\n",
    "\\frac{\\partial y_1}{\\partial x_1} & \\cdots & 0 \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "0 & \\cdots & \\frac{\\partial y_n}{\\partial x_n}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    ":::\n",
    "\n",
    "The multiplication of a diagonal matrix with a vector is equivalent to elementwise multiplication of the vector with the diagonal elements of the matrix.\n",
    "\n",
    "\n",
    ":::{#exm-relu-times-vec}\n",
    "## ReLU Applied Elementwise to a Vector multiplied by a Vector\n",
    "\n",
    "Let $f: \\mathbb{R} \\to \\mathbb{R}$ be some (differentiable) scalar function and let $\\delta, x \\in \\mathbb{R}^{n}$. Then the derivative of $y = f(x) \\cdot x$ with respect to $x$ is a diagonal matrix with the derivative of $f$ with respect to $x_i$ on the diagonal.\n",
    "\n",
    "$$\n",
    "\\delta \\frac{\\partial y}{\\partial x} = \\begin{pmatrix} \\delta_1 \\\\ \\vdots \\\\ \\delta_n \\end{pmatrix} \\begin{pmatrix}\n",
    "\\frac{\\partial y_1}{\\partial x_1} & \\cdots & 0 \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "0 & \\cdots & \\frac{\\partial y_n}{\\partial x_n}\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix} \\delta_1 \\frac{\\partial y_1}{\\partial x_1} \\\\ \\vdots \\\\ \\delta_n \\frac{\\partial y_n}{\\partial x_n} \\end{pmatrix}\n",
    "= \\delta \\odot \\begin{pmatrix} \\frac{\\partial y_1}{\\partial x_1} \\\\ \\vdots \\\\ \\frac{\\partial y_n}{\\partial x_n} \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "The symbol $\\odot$ denotes elementwise multiplication.\n",
    ":::\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ta2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
