{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractive Text Summarization\n",
    "\n",
    "- Split the document into sentences (sentence tokenization)\n",
    "- Assign a score to each sentence\n",
    "- Pick the top N sentences\n",
    "\n",
    "\n",
    "- Score = Average (non-zero TF-IDF of words in the sentence) (unimportant words -> smaller value). Important words appearing more often in the sentence will have an even higher score. Mean -> avoid bias towards longer sentences. Non-zero -> TF-IDF very sparse (don't want to choose based on variety of words)\n",
    "\n",
    "- TextRank score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textwrap\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/amarov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/amarov/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/amarov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://github.com/febse/data/raw/refs/heads/main/ta/BBC%20News%20Train.csv.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worldcom ex-boss launches defence lawyers defending former worldcom\n",
      "chief bernie ebbers against a battery of fraud charges have called a\n",
      "company whistleblower as their first witness.  cynthia cooper\n",
      "worldcom s ex-head of internal accounting  alerted directors to\n",
      "irregular accounting practices at the us telecoms giant in 2002. her\n",
      "warnings led to the collapse of the firm following the discovery of an\n",
      "$11bn (£5.7bn) accounting fraud.  mr ebbers has pleaded not guilty to\n",
      "charges of fraud and conspiracy.  prosecution lawyers have argued that\n",
      "mr ebbers orchestrated a series of accounting tricks at worldcom\n",
      "ordering employees to hide expenses and inflate revenues to meet wall\n",
      "street earnings estimates.  but ms cooper  who now runs her own\n",
      "consulting business  told a jury in new york on wednesday that\n",
      "external auditors arthur andersen had approved worldcom s accounting\n",
      "in early 2001 and 2002. she said andersen had given a  green light  to\n",
      "the procedures and practices used by worldcom.  mr ebber s lawyers\n",
      "have said he was unaware of the fraud  arguing that auditors did not\n",
      "alert him to any problems.  ms cooper also said that during\n",
      "shareholder meetings mr ebbers often passed over technical questions\n",
      "to the company s finance chief  giving only  brief  answers himself.\n",
      "the prosecution s star witness  former worldcom financial chief scott\n",
      "sullivan  has said that mr ebbers ordered accounting adjustments at\n",
      "the firm  telling him to  hit our books . however  ms cooper said mr\n",
      "sullivan had not mentioned  anything uncomfortable  about worldcom s\n",
      "accounting during a 2001 audit committee meeting.  mr ebbers could\n",
      "face a jail sentence of 85 years if convicted of all the charges he is\n",
      "facing.  worldcom emerged from bankruptcy protection in 2004  and is\n",
      "now known as mci.  last week  mci agreed to a buyout by verizon\n",
      "communications in a deal valued at $6.75bn.\n"
     ]
    }
   ],
   "source": [
    "doc = df.iloc[0]\n",
    "\n",
    "print(textwrap.fill(doc[\"Text\"], replace_whitespace=False, fix_sentence_endings=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['worldcom ex-boss launches defence lawyers defending former worldcom chief bernie ebbers against a battery of fraud charges have called a company whistleblower as their first witness.',\n",
       " 'cynthia cooper  worldcom s ex-head of internal accounting  alerted directors to irregular accounting practices at the us telecoms giant in 2002. her warnings led to the collapse of the firm following the discovery of an $11bn (£5.7bn) accounting fraud.',\n",
       " 'mr ebbers has pleaded not guilty to charges of fraud and conspiracy.',\n",
       " 'prosecution lawyers have argued that mr ebbers orchestrated a series of accounting tricks at worldcom  ordering employees to hide expenses and inflate revenues to meet wall street earnings estimates.',\n",
       " 'but ms cooper  who now runs her own consulting business  told a jury in new york on wednesday that external auditors arthur andersen had approved worldcom s accounting in early 2001 and 2002. she said andersen had given a  green light  to the procedures and practices used by worldcom.',\n",
       " 'mr ebber s lawyers have said he was unaware of the fraud  arguing that auditors did not alert him to any problems.',\n",
       " 'ms cooper also said that during shareholder meetings mr ebbers often passed over technical questions to the company s finance chief  giving only  brief  answers himself.',\n",
       " 'the prosecution s star witness  former worldcom financial chief scott sullivan  has said that mr ebbers ordered accounting adjustments at the firm  telling him to  hit our books .',\n",
       " 'however  ms cooper said mr sullivan had not mentioned  anything uncomfortable  about worldcom s accounting during a 2001 audit committee meeting.',\n",
       " 'mr ebbers could face a jail sentence of 85 years if convicted of all the charges he is facing.',\n",
       " 'worldcom emerged from bankruptcy protection in 2004  and is now known as mci.',\n",
       " 'last week  mci agreed to a buyout by verizon communications in a deal valued at $6.75bn.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sents = sent_tokenize(doc[\"Text\"])\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))\n",
    "\n",
    "X = vectorizer.fit_transform(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 137)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row-wise Mean of Non-zero Elements:\n",
      " [0.2269258  0.1987996  0.36673461 0.21409173 0.18696719 0.30947282\n",
      " 0.23131543 0.22443098 0.25194776 0.29554142 0.371702   0.31593632]\n"
     ]
    }
   ],
   "source": [
    "X = X.toarray()\n",
    "scores = np.array([np.mean(row[row != 0]) for row in X])\n",
    "print(\"Row-wise Mean of Non-zero Elements:\\n\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top sentences:\n",
      "\n",
      "0.37: worldcom emerged from bankruptcy protection in 2004  and is now known as mci.\n",
      "0.37: mr ebbers has pleaded not guilty to charges of fraud and conspiracy.\n",
      "0.32: last week  mci agreed to a buyout by verizon communications in a deal valued at $6.75bn.\n",
      "0.31: mr ebber s lawyers have said he was unaware of the fraud  arguing that auditors did not alert him to any problems.\n",
      "0.30: mr ebbers could face a jail sentence of 85 years if convicted of all the charges he is facing.\n"
     ]
    }
   ],
   "source": [
    "print(\"Top sentences:\\n\")\n",
    "\n",
    "for i in sort_idx[:5]:\n",
    "  print(f\"%.2f: %s\" % (scores[i], sents[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextRank\n",
    "\n",
    "TextRank is an unsupervised keyword and sentence extraction algorithm that is based on PageRank. Before we can see how to apply TextRank to text summarization, we need to understand how PageRank works.\n",
    "\n",
    "PageRank is a link analysis algorithm that assigns a numerical weighting to each element of a hyperlinked set of documents, such as the World Wide Web, with the purpose of \"measuring\" its relative importance within the set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "graph TD\n",
    "    A[Page A] -->|Link| B[Page B]\n",
    "    A -->|Link| C[Page C]\n",
    "    B -->|Link| D[Page D]\n",
    "    C -->|Link| D\n",
    "    D -->|Link| A\n",
    "    D -->|Link| E[Page E]\n",
    "    E -->|Link| B\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a walk through the web. We start at a random webpage and follow a random link on that page. On the next page, we again follow a randomly choosen link. We keep doing this for a long time. We can ask a question: what is the probability that we end up on a certain page?\n",
    "\n",
    "We can view this walk as a Markov chain. Say that all pages are $n$ and let's assume that we can reach any page from any other page (though not \n",
    "with the same probability).\n",
    "\n",
    "Let $s_t$ be the page we are on at time $t$. The probability of moving from page $i$ to page $j$ is given by\n",
    "\n",
    "$$\n",
    "P_{ij} = p(s_{t+1} = j | s_t = i)\n",
    "$$\n",
    "\n",
    "The probability of being on page $i$ at time $t+1$ is given by\n",
    "\n",
    "$$\n",
    "p(s_{t+1} = i) = \\sum_{j=1}^n p(s_{t+1} = i | s_t = j) p(s_t = j)\n",
    "$$\n",
    "\n",
    "or in matrix form\n",
    "\n",
    "$$\n",
    "p_{t+1} = p_t P\n",
    "$$\n",
    "\n",
    "where $p_t$ is a row vector with the probability of being on each page at time $t$.\n",
    "\n",
    "The matrix $P$ is called the transition matrix. It is a square matrix with $n$ rows and columns. The rows sum to 1 (the probability of moving to any page is 1). What happens when we walk for a long time, is there a unique distribution of pages we end up on? \n",
    "\n",
    "The answer is given by the Frobenius-Perron theorem that proofs that the if the Markov chain is ergodic (you can reach any page from any other page), then there is a unique stationary distribution of pages.\n",
    "\n",
    "$$\n",
    "p_{\\infty} = p_{\\infty} P\n",
    "$$\n",
    "\n",
    "The last equation also tells us how to calculate the stationary distribution as it is an eigenvector equation for the eigenvalue equal to one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2 0.8]\n",
      "[0.14 0.86]\n",
      "[0.128 0.872]\n",
      "[0.1256 0.8744]\n",
      "[0.12512 0.87488]\n",
      "[0.125024 0.874976]\n",
      "[0.1250048 0.8749952]\n",
      "[0.12500096 0.87499904]\n",
      "[0.12500019 0.87499981]\n",
      "[0.12500004 0.87499996]\n",
      "[0.12500001 0.87499999]\n",
      "[0.125 0.875]\n",
      "[0.125 0.875]\n",
      "[0.125 0.875]\n"
     ]
    }
   ],
   "source": [
    "P = np.array([[0.3, 0.7], [0.1, 0.9]])\n",
    "\n",
    "p0 = np.array([0.5, 0.5])\n",
    "\n",
    "for i in range(14):\n",
    "    p0 = p0.dot(P)\n",
    "    print(p0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [0.2 1. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678, -0.14142136],\n",
       "       [ 0.70710678, -0.98994949]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the eigenvalues and eigenvectors of P\n",
    "eigenvalues, eigenvectors = np.linalg.eig(P.T)\n",
    "\n",
    "print(\"Eigenvalues:\", eigenvalues)\n",
    "eigenvectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.125, 0.875])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eigenvectors are unique up to a scalar multiple\n",
    "\n",
    "eigenvectors.T[1] / eigenvectors.T[1].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PageRank algorithm applies smoothing to the transition matrix as in practice it is not possible for every page to link to every other page.\n",
    "\n",
    "The smoothing is done by adding a damping factor $d$ to the transition matrix\n",
    "\n",
    "$$\n",
    "P = \\alpha T + (1-\\alpha) E, \\quad \\alpha \\in [0, 1]\n",
    "$$\n",
    "\n",
    "where $T$ is the original transition matrix and $E$ is a matrix with all elements equal to $1/n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TextRank algorithm scores sentences based on the stationary distribution of a Markov chain. Instead of webpages we have sentences. There are no real transition probabilities between sentences, but we can use the cosine similarity between the sentence representations in the TF-IDF space as a proxy.\n",
    "\n",
    "Let's implement it as an exercise.\n",
    "\n",
    "- Compute the TF-IDF matrix of the sentences\n",
    "- Compute the cosine similarity matrix\n",
    "- Normalize the cosine similarity matrix to get the transition matrix\n",
    "- Smooth the transition matrix\n",
    "- Compute the stationary distribution\n",
    "- Rank the sentences based on the stationary distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nUK retail sales fell in December, failing to meet expectations and making it by some counts the worst Christmas since 1981.',\n",
       " 'Retail sales dropped by 1% on the month in December, after a 0.6% rise in November, the Office for National Statistics (ONS) said.',\n",
       " 'The ONS revised the annual 2004 rate of growth down from the 5.9% estimated in November to 3.2%.',\n",
       " 'A number of retailers have already reported poor figures for December.',\n",
       " 'Clothing retailers and non-specialist stores were the worst hit with only internet retailers showing any significant growth, according to the ONS.',\n",
       " 'The last time retailers endured a tougher Christmas was 23 years previously, when sales plunged 1.7%.',\n",
       " 'The ONS echoed an earlier caution from Bank of England governor Mervyn King not to read too much into the poor December figures.',\n",
       " 'Some analysts put a positive gloss on the figures, pointing out that the non-seasonally-adjusted figures showed a performance comparable with 2003.',\n",
       " 'The November-December jump last year was roughly comparable with recent averages, although some way below the serious booms seen in the 1990s.',\n",
       " 'And figures for retail volume outperformed measures of actual spending, an indication that consumers are looking for bargains, and retailers are cutting their prices.',\n",
       " 'However, reports from some High Street retailers highlight the weakness of the sector.',\n",
       " 'Morrisons, Woolworths, House of Fraser, Marks & Spencer and Big Food all said that the festive period was disappointing.',\n",
       " 'And a British Retail Consortium survey found that Christmas 2004 was the worst for 10 years.',\n",
       " 'Yet, other retailers - including HMV, Monsoon, Jessops, Body Shop and Tesco - reported that festive sales were well up on last year.',\n",
       " 'Investec chief economist Philip Shaw said he did not expect the poor retail figures to have any immediate effect on interest rates.',\n",
       " '\"The retail sales figures are very weak, but as Bank of England governor Mervyn King indicated last night, you don\\'t really get an accurate impression of Christmas trading until about Easter,\" said Mr Shaw.',\n",
       " '\"Our view is the Bank of England will keep its powder dry and wait to see the big picture.\"']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sents\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ta2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
